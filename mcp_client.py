
import asyncio
import sys
import os
import json
from typing import Optional, Dict, Any
from contextlib import AsyncExitStack
from pathlib import Path

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()  # ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡

# --- æ•°æ®ç»“æ„ ---
# ä¸ºæ¯ä¸ªè¿æ¥åˆ›å»ºä¸€ä¸ªç®€å•çš„æ•°æ®å®¹å™¨ï¼Œæ–¹ä¾¿ç®¡ç†
class ServerConnection:
    def __init__(self, session: ClientSession, exit_stack: AsyncExitStack, tools: list):
        self.session = session
        self.exit_stack = exit_stack
        self.tools = tools

class MCPManager:
    """
    ä¸€ä¸ªå¯ä»¥ç®¡ç†å¤šä¸ª MCP æœåŠ¡å™¨è¿æ¥çš„ç®¡ç†å™¨ã€‚
    å®ƒè´Ÿè´£è¿æ¥ã€è·¯ç”±å·¥å…·è°ƒç”¨å’Œç”Ÿå‘½å‘¨æœŸç®¡ç†ã€‚
    """
    def __init__(self):
        """
        åˆå§‹åŒ– MCPManagerã€‚
        """
        # self.connections å­—å…¸å°†æœåŠ¡å™¨IDæ˜ å°„åˆ° ServerConnection å¯¹è±¡
        self.connections: Dict[str, ServerConnection] = {}
        # OpenAI å®¢æˆ·ç«¯å¯ä»¥è¢«æ‰€æœ‰ä¼šè¯å…±äº«
        self.client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=os.getenv("OPENROUTER_API_KEY"),
        )
        # ç”¨äºç”Ÿæˆå”¯ä¸€å·¥å…·åç§°çš„åˆ†éš”ç¬¦
        self.TOOL_NAME_SEPARATOR = "__"

    def _create_server_id(self, script_path: str) -> str:
        """æ ¹æ®è„šæœ¬è·¯å¾„åˆ›å»ºä¸€ä¸ªç®€çŸ­ã€å”¯ä¸€çš„æœåŠ¡å™¨IDã€‚"""
        return Path(script_path).stem.replace(" ", "_")

    async def connect_to_server(self, server_script_path: str):
        """
        è¿æ¥åˆ°ä¸€ä¸ªæ–°çš„ MCP æœåŠ¡å™¨å¹¶å­˜å‚¨å…¶ä¼šè¯ã€‚

        Args:
            server_script_path: æœåŠ¡å™¨è„šæœ¬çš„è·¯å¾„ (.py or .js)ã€‚
        """
        server_id = self._create_server_id(server_script_path)
        if server_id in self.connections:
            print(f"è­¦å‘Šï¼šå·²è¿æ¥åˆ°æœåŠ¡å™¨ '{server_id}'ã€‚è·³è¿‡é‡å¤è¿æ¥ã€‚")
            return

        print(f"æ­£åœ¨è¿æ¥åˆ°æœåŠ¡å™¨ '{server_id}' (æ¥è‡ª {server_script_path})...")

        is_python = server_script_path.endswith('.py')
        is_js = server_script_path.endswith('.js')
        if not (is_python or is_js):
            raise ValueError("æœåŠ¡å™¨è„šæœ¬å¿…é¡»æ˜¯ .py æˆ– .js æ–‡ä»¶")

        command = "python" if is_python else "node"
        server_params = StdioServerParameters(
            command=command,
            args=[server_script_path],
            env=None
        )
        
        # æ¯ä¸ªè¿æ¥éƒ½éœ€è¦è‡ªå·±çš„ AsyncExitStack æ¥ç‹¬ç«‹ç®¡ç†å…¶ç”Ÿå‘½å‘¨æœŸ
        exit_stack = AsyncExitStack()
        try:
            stdio_transport = await exit_stack.enter_async_context(stdio_client(server_params))
            stdio, write = stdio_transport
            session = await exit_stack.enter_async_context(ClientSession(stdio, write))

            await session.initialize()

            response = await session.list_tools()
            tools = response.tools
            
            # å­˜å‚¨è¿æ¥ä¿¡æ¯
            self.connections[server_id] = ServerConnection(session, exit_stack, tools)
            print(f"âœ… æˆåŠŸè¿æ¥åˆ° '{server_id}'ï¼Œå¯ç”¨å·¥å…·: {[tool.name for tool in tools]}")

        except Exception as e:
            print(f"âŒ è¿æ¥åˆ° '{server_id}' å¤±è´¥: {e}")
            # å¦‚æœè¿æ¥å¤±è´¥ï¼Œç¡®ä¿æ¸…ç†å·²åˆ›å»ºçš„èµ„æº
            await exit_stack.aclose()
            raise

    def _get_all_tools_for_llm(self) -> list:
        """
        æ•´åˆæ‰€æœ‰å·²è¿æ¥æœåŠ¡å™¨çš„å·¥å…·ï¼Œå¹¶ä¸ºå®ƒä»¬åˆ›å»ºå”¯ä¸€çš„åç§°ï¼Œ
        ä»¥ä¾¿è¯­è¨€æ¨¡å‹å¯ä»¥åŒºåˆ†å®ƒä»¬ã€‚
        """
        all_tools = []
        for server_id, conn in self.connections.items():
            for tool in conn.tools:
                # æ ¼å¼: {server_id}__{tool_name}
                unique_tool_name = f"{server_id}{self.TOOL_NAME_SEPARATOR}{tool.name}"
                all_tools.append({
                    "type": "function",
                    "function": {
                        "name": unique_tool_name,
                        "description": f"[æ¥è‡ªæœåŠ¡å™¨: {server_id}] {tool.description}",
                        "parameters": tool.inputSchema
                    }
                })
        return all_tools

    async def process_query(self, query: str) -> str:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢ã€‚å®ƒä¼šå°†æ‰€æœ‰å¯ç”¨å·¥å…·å‘é€ç»™è¯­è¨€æ¨¡å‹ï¼Œ
        å¹¶æ ¹æ®æ¨¡å‹çš„é€‰æ‹©å°†å·¥å…·è°ƒç”¨è·¯ç”±åˆ°æ­£ç¡®çš„æœåŠ¡å™¨ã€‚

        Args:
            query: ç”¨æˆ·çš„æŸ¥è¯¢ã€‚

        Returns:
            è¯­è¨€æ¨¡å‹çš„æœ€ç»ˆå“åº”ã€‚
        """
        if not self.connections:
            return "é”™è¯¯ï¼šæœªè¿æ¥åˆ°ä»»ä½•æœåŠ¡å™¨ã€‚è¯·å…ˆè¿æ¥æœåŠ¡å™¨ã€‚"

        messages = [{"role": "user", "content": query}]
        available_tools = self._get_all_tools_for_llm()

        # ç¬¬ä¸€æ¬¡è°ƒç”¨è¯­è¨€æ¨¡å‹
        completion = self.client.chat.completions.create(
            extra_headers={
                "HTTP-Referer": os.getenv("YOUR_SITE_URL", ""),
                "X-Title": os.getenv("YOUR_SITE_NAME", ""),
            },
            model="anthropic/claude-3.5-sonnet",
            messages=messages,
            tools=available_tools,
            tool_choice="auto"
        )

        response_message = completion.choices[0].message
        final_text = []

        if response_message.content:
            final_text.append(response_message.content)

        # å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆå¦‚æœæœ‰ï¼‰
        if response_message.tool_calls:
            messages.append(response_message)
            for tool_call in response_message.tool_calls:
                unique_function_name = tool_call.function.name
                
                # è§£æå”¯ä¸€çš„å·¥å…·åç§°ä»¥æ‰¾åˆ° server_id å’ŒåŸå§‹å·¥å…·åç§°
                try:
                    server_id, original_function_name = unique_function_name.split(self.TOOL_NAME_SEPARATOR, 1)
                except ValueError:
                    print(f"é”™è¯¯ï¼šæ— æ³•è§£æå·¥å…·åç§° '{unique_function_name}'")
                    continue
                
                function_args_str = tool_call.function.arguments
                
                if server_id not in self.connections:
                    print(f"é”™è¯¯ï¼šæ¨¡å‹å°è¯•è°ƒç”¨ä¸€ä¸ªä¸å­˜åœ¨æˆ–æœªè¿æ¥çš„æœåŠ¡å™¨ '{server_id}' çš„å·¥å…·ã€‚")
                    continue

                print(f"â–¶ï¸ æ­£åœ¨è·¯ç”±è°ƒç”¨åˆ°æœåŠ¡å™¨ '{server_id}' -> å·¥å…· '{original_function_name}'...")
                final_text.append(f"[è°ƒç”¨æœåŠ¡å™¨ '{server_id}' çš„å·¥å…· {original_function_name}ï¼Œå‚æ•°: {function_args_str}]")

                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                try:
                    # ä½¿ç”¨ json.loads è€Œä¸æ˜¯ evalï¼Œæ›´å®‰å…¨
                    function_args = json.loads(function_args_str)
                    target_session = self.connections[server_id].session
                    result = await target_session.call_tool(original_function_name, function_args)
                    
                    # å°†å·¥å…·ç»“æœé™„åŠ åˆ°æ¶ˆæ¯å†å²ä¸­
                    messages.append({
                        "tool_call_id": tool_call.id,
                        "role": "tool",
                        "name": unique_function_name,
                        "content": result.content,
                    })
                except Exception as e:
                    error_content = f"æ‰§è¡Œå·¥å…·æ—¶å‡ºé”™: {e}"
                    print(f"âŒ {error_content}")
                    messages.append({
                        "tool_call_id": tool_call.id,
                        "role": "tool",
                        "name": unique_function_name,
                        "content": error_content,
                    })


            # ç¬¬äºŒæ¬¡è°ƒç”¨è¯­è¨€æ¨¡å‹ï¼Œé™„å¸¦å·¥å…·è°ƒç”¨çš„ç»“æœ
            second_completion = self.client.chat.completions.create(
                model="anthropic/claude-3.5-sonnet",
                messages=messages,
            )
            final_text.append(second_completion.choices[0].message.content)

        return "\n".join(final_text)

    async def cleanup(self):
        """
        æ¸…ç†æ‰€æœ‰èµ„æºå¹¶å…³é—­æ‰€æœ‰æœåŠ¡å™¨è¿æ¥ã€‚
        """
        print("\næ­£åœ¨å…³é—­æ‰€æœ‰æœåŠ¡å™¨è¿æ¥...")
        for server_id, conn in self.connections.items():
            try:
                await conn.exit_stack.aclose()
                print(f"ğŸ”Œ è¿æ¥ '{server_id}' å·²å…³é—­ã€‚")
            except Exception as e:
                print(f"å…³é—­è¿æ¥ '{server_id}' æ—¶å‡ºé”™: {e}")
        self.connections.clear()


async def chat_loop(manager: MCPManager):
    """
    è¿è¡Œä¸»äº¤äº’å¼èŠå¤©å¾ªç¯ã€‚
    """
    print("\nå¤šæœåŠ¡å™¨ MCP å®¢æˆ·ç«¯å·²å¯åŠ¨ï¼")
    print("è¾“å…¥æ‚¨çš„æŸ¥è¯¢ï¼Œæˆ–è¾“å…¥ 'quit' é€€å‡ºã€‚")

    while True:
        try:
            query = input("\næŸ¥è¯¢: ").strip()

            if query.lower() == 'quit':
                break

            response = await manager.process_query(query)
            print("\n" + response)

        except (KeyboardInterrupt, EOFError):
            print("\næ£€æµ‹åˆ°é€€å‡ºä¿¡å·ã€‚")
            break
        except Exception as e:
            print(f"\nå‘ç”Ÿé”™è¯¯: {str(e)}")


async def main():
    """
    ä¸»å‡½æ•°ï¼Œç”¨äºè¿è¡Œå®¢æˆ·ç«¯ã€‚
    """
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python client.py <path_to_server1> [<path_to_server2> ...]")
        sys.exit(1)

    manager = MCPManager()
    server_scripts = sys.argv[1:]
    
    # å¹¶å‘è¿æ¥åˆ°æ‰€æœ‰æŒ‡å®šçš„æœåŠ¡å™¨
    connect_tasks = [manager.connect_to_server(script) for script in server_scripts]
    await asyncio.gather(*connect_tasks, return_exceptions=True)

    if not manager.connections:
        print("\næœªèƒ½è¿æ¥åˆ°ä»»ä½•æœåŠ¡å™¨ã€‚æ­£åœ¨é€€å‡ºã€‚")
        sys.exit(1)

    try:
        await chat_loop(manager)
    finally:
        await manager.cleanup()

if __name__ == "__main__":
    asyncio.run(main())
